{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "03.2 - Compiling and training a sequential model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV4fDVHrnlyT"
      },
      "source": [
        "# Exercise 03.2 - Keras Sequential Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWghY66inlyW"
      },
      "source": [
        "Before you can start, you have to find a GPU on the system that is not heavily used by other users. Otherwise you cannot initialize your neural network.\n",
        "\n",
        "\n",
        "**Hint:** the command is **nvidia-smi**, just in case it is displayed above in two lines because of a line break.\n",
        "\n",
        "As a result you get a summary of the GPUs available in the system, their current memory usage (in MiB for megabytes), and their current utilization (in %). There should be six or eight GPUs listed and these are numbered 0 to n-1 (n being the number of GPUs). The GPU numbers (ids) are quite at the beginning of each GPU section and their numbers increase from top to bottom by 1.\n",
        "\n",
        "Find a GPU where the memory usage is low. For this purpose look at the memory usage, which looks something like '365MiB / 16125MiB'. The first value is the already used up memory and the second value is the total memory of the GPU. Look for a GPU where there is a large difference between the first and the second value.\n",
        "\n",
        "**Remember the GPU id and write it in the next line instead of the character X.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6PaAnmZnlyX"
      },
      "source": [
        "# Change X to the GPU number you want to use,\n",
        "# otherwise you will get a Python error\n",
        "# e.g. USE_GPU = 4\n",
        "USE_GPU = 0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5xkXlVInlyZ"
      },
      "source": [
        "Alternatively, you can use the terminal command in the Jupyter notebook by prefixing the command with an exclamation mark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTV4H_Chnlya",
        "outputId": "99848e7e-2ade-462d-d774-3d1cb78d5854"
      },
      "source": [
        "# Alternatively, you can use the magic \n",
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 10 11:55:07 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    29W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0aMQ8v6nlya"
      },
      "source": [
        "### Choose one GPU\n",
        "\n",
        "**The following code is very important and must always be executed before using TensorFlow in the exercises, so that only one GPU is used and that it is set in a way that not all its memory is used at once. Otherwise, the other students will not be able to work with this GPU.**\n",
        "\n",
        "The following program code imports the TensorFlow library for Deep Learning and outputs the version of the library.\n",
        "\n",
        "Then, TensorFlow is configured to only see the one GPU whose number you wrote in the above cell (USE_GPU = X) instead of the X.\n",
        "\n",
        "Finally, the GPU is set so that it does not immediately reserve all memory, but only uses more memory when needed. \n",
        "\n",
        "(The comments within the code cell explains a bit of what is happening if you are interested to better understand it. See also the documentation of TensorFlow for an explanation of the used methods.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXp_ez43nlyb",
        "outputId": "20bec1a2-45e2-4c47-9581-a1beaa78be4c"
      },
      "source": [
        "# Import TensorFlow \n",
        "import tensorflow as tf\n",
        "\n",
        "# Print the installed TensorFlow version\n",
        "print(f'TensorFlow version: {tf.__version__}\\n')\n",
        "\n",
        "# Get all GPU devices on this server\n",
        "gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "# Print the name and the type of all GPU devices\n",
        "print('Available GPU Devices:')\n",
        "for gpu in gpu_devices:\n",
        "    print(' ', gpu.name, gpu.device_type)\n",
        "    \n",
        "# Set only the GPU specified as USE_GPU to be visible\n",
        "tf.config.set_visible_devices(gpu_devices[USE_GPU], 'GPU')\n",
        "\n",
        "# Get all visible GPU  devices on this server\n",
        "visible_devices = tf.config.get_visible_devices('GPU')\n",
        "\n",
        "# Print the name and the type of all visible GPU devices\n",
        "print('\\nVisible GPU Devices:')\n",
        "for gpu in visible_devices:\n",
        "    print(' ', gpu.name, gpu.device_type)\n",
        "    \n",
        "# Set the visible device(s) to not allocate all available memory at once,\n",
        "# but rather let the memory grow whenever needed\n",
        "for gpu in visible_devices:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.7.0\n",
            "\n",
            "Available GPU Devices:\n",
            "  /physical_device:GPU:0 GPU\n",
            "\n",
            "Visible GPU Devices:\n",
            "  /physical_device:GPU:0 GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNvhGdlxnlyc"
      },
      "source": [
        "# Introduction to the Keras Sequential Model\n",
        "\n",
        "### Part II: Training a keras model\n",
        "\n",
        "In the previous section of this tutorial you have learned to build neural networks using the Sequential API. In this notebook you will learn how to configurate the training process and to train the model.\n",
        "\n",
        "## Learning objectives\n",
        "\n",
        "- configurate the learning process via `compile` method\n",
        "- understand the various ways for passing in the required arguments to the `compile` method\n",
        "- learn how to launch the training process  \n",
        "- learn to evaluate the trained model\n",
        "- learn to make predictions on test/new data\n",
        "\n",
        "\n",
        "\n",
        "For this purpose we will build a lassification network for classifing  [MNIST](http://yann.lecun.com/exdb/mnist/) dataset of handwritten digits. It includes a training set of 60,000 examples, and a test set of 10,000 examples.\n",
        "The data is available in [keras.datasets API](https://www.tensorflow.org/api_docs/python/tf/keras/datasets)  which provides some utility functions to fetch and load common datasets.  We can be load the data using the `load_data()` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu6iTcg0nlye"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import  Flatten, Dense"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQN33ASZnlyf",
        "outputId": "19cab1e7-817b-478a-e555-7be64564ee91"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVYMarHQnlyf",
        "outputId": "cb01ee91-f32a-460e-d265-7d6b186be4b4"
      },
      "source": [
        "print(X_train_full.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW-Wac4rnlyg",
        "outputId": "6ec2814c-122d-4d9b-bbea-e963b03ea77c"
      },
      "source": [
        "print(X_train_full.dtype)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvMcGwNinlyg"
      },
      "source": [
        "- As you can observe, dataset is already split into a training set and a test set, but there is no\n",
        "validation set, so we will put aside 5000 example for validation purposes.\n",
        "- Moreover we will scale the input features, which improves the optimization process. For simplicity, we just\n",
        "scale the pixel intensities down to the 0-1 range by dividing them by 255.0 (this also\n",
        "converts them to floats):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6h8DMUanlyh"
      },
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJbwiF7-nlyh"
      },
      "source": [
        "As you already learend in the first section of the tutorial, firstly, we import the `sequential` class from `tensorflow.keras.models`. We're also importing the `Flatten` and `Dense` layer from `tensorflow.keras.layers`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlWu691Anlyh"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import  Flatten, Dense"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jZ1kKG7nlyi"
      },
      "source": [
        "model = Sequential()                           # creates a Sequential model object\n",
        "model.add(Flatten(input_shape=[28, 28]))       # to convert each input image into a 1D array, specify the input_shape because it is the first layer\n",
        "model.add(Dense(300, activation=\"relu\", name = 'first_hidden'))       # Dense hidden layer with 300 neurons, ReLU non-linearity\n",
        "model.add(Dense(10, activation =\"softmax\", name = 'output_layer'))     #  output layer with 10 neurons (one per class)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK6Mn_xYnlyi",
        "outputId": "5ce827fc-bc92-435a-b443-e201953e56d9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " first_hidden (Dense)        (None, 300)               235500    \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 238,510\n",
            "Trainable params: 238,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsMPUhOxnlyj"
      },
      "source": [
        "### Configurate the learning process \n",
        "\n",
        "We build a keras model and  configurate the learning process via the `compile()` function which expects three important arguments:\n",
        "\n",
        "   - An optimizer-  This could be the string identifier of an existing optimizer (e.g. as “rmsprop” or “adagrad”) or a call to an optimizer function (e.g. tensorflow.keras.optimizers.SGD()).\n",
        "\n",
        "   - A loss function. This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (e.g. “binary_crossentropy” or “mse”) or a call to a loss function (e.g. tf.keras.losses.binary_crossentropy()).\n",
        "\n",
        "   - A list of metrics. For any classification problem you will want to set this to metrics = ['accuracy']. A metric could be the string identifier of an existing metric or a call to metric function (e.g. tf.keras.metrics.categorical_accuracy).\n",
        " \n",
        "\n",
        "\n",
        "In the image below you can see the required and optional arguments to be passed to the copile method:\n",
        "<center>\n",
        "<img src ='images/keras_compile.png', style = \"zoom: 75%\">\n",
        "   \n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59eAXvDjnlyu"
      },
      "source": [
        "\n",
        "The possible values for the keywords arguments can be found at:\n",
        "[Optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers), \n",
        "[Losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses), \n",
        "[Metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEDBCsAKnlyu"
      },
      "source": [
        "# Define the model optimizer, loss function and metrics\n",
        "model.compile(optimizer ='sgd', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7o85Q_4nlyu"
      },
      "source": [
        "#### Training\n",
        "\n",
        "We train a built model by calling `model.fit()`and pass it the `input features (X_train)` and the `target classes (y_train)`, as\n",
        "well as the `number of epochs to train` (or else it would default to just 1, which would\n",
        "definitely not be enough to converge to a good solution). </br>\n",
        "During this proccess, by applying the chosen optimization algorithm when we compiled the model, the model weights are iterratively updated till the value of the cost function is minimized. </br>\n",
        "Another relevant argument of the `fit()` method is the `batch_size`. It specifies the number of training examples used during a training epoch (default value is 32 and works the best in most cases).\n",
        "\n",
        "Optionally, we can also pass a validation set: Keras will measure the loss and the extra metrics on this set at the\n",
        "end of each epoch, which is very useful to see how well the model really performs: if\n",
        "the performance on the training set is much better than on the validation set, your model is overfitting (you will learn about this concept in a couple of weeks).\n",
        "\n",
        "As you can see in the print screen shown below, the fit method supports many other arguments. Please check the documentation for further details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3l_1GWHnlyu",
        "outputId": "b3e39746-9274-400b-a417-d681c286d254"
      },
      "source": [
        "history = model.fit(x = X_train, y= y_train, epochs = 5, batch_size = 32, validation_data=(X_valid, y_valid) )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 10s 4ms/step - loss: 0.6308 - accuracy: 0.8473 - val_loss: 0.3594 - val_accuracy: 0.9050\n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3379 - accuracy: 0.9049 - val_loss: 0.2874 - val_accuracy: 0.9216\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2885 - accuracy: 0.9183 - val_loss: 0.2565 - val_accuracy: 0.9298\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2572 - accuracy: 0.9281 - val_loss: 0.2300 - val_accuracy: 0.9396\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2336 - accuracy: 0.9346 - val_loss: 0.2120 - val_accuracy: 0.9444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lgcu7lBsnlyv"
      },
      "source": [
        "The returned \"history\" object has the attribute 'history' which is a dictionary that holds a record of the loss values and metric values during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d035YIPynlyv",
        "outputId": "2f4feeb9-3b87-468a-c023-61be2fcadba5"
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZAHbT1Hnlyv",
        "outputId": "2795a68b-ef94-4074-af61-f278801249b3"
      },
      "source": [
        "# getting the loss for all training epochs\n",
        "history.history['loss']"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6308482885360718,\n",
              " 0.3378755748271942,\n",
              " 0.2884528636932373,\n",
              " 0.2571693956851959,\n",
              " 0.23355156183242798]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQeLHOqXnlyv"
      },
      "source": [
        "### Evaluating the model\n",
        "Once we are satisfied with your thee validation accuracy, we can evaluate it on the test set to estimate the generalization error\n",
        "before  deploying the model to production. \n",
        "We can easily do this by calling the `evaluate()` method on the trained model object (it also supports several other arguments, such as `batch_size` or `sample_weight`, please check the documentation for more details).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nBYWw98nlyv",
        "outputId": "8fe688c9-e760-4824-83b6-89fefd67b340"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 27.8222 - accuracy: 0.9371\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[27.82224464416504, 0.9370999932289124]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvxR3Tk3nlyv"
      },
      "source": [
        "### Using the model to make predictions\n",
        "\n",
        "\n",
        "We can call the `predict()` method on the trained object model to make predictions on new instances.\n",
        "Since we don’t have actual new instances, we will just use the first 3 instances of the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLwnvEiknlyw",
        "outputId": "e13d589b-74fd-431c-96da-b783c6037c20"
      },
      "source": [
        "X_new = X_test[:3]\n",
        "classifications = model.predict(X_new)\n",
        "print(classifications[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJi7XcvHnlyw"
      },
      "source": [
        "### Important observation\n",
        "As we have saw in the previous section of the tutorial (for activation functions), Keras provides the possibility for setting up the models in the form of **readable strings** that can be passed in to many of the options in the Keras API (also to the options in the compile method).\n",
        "It is important to know that each of these strings is a **reference to another object or function** and we can always use that object or function directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX_RsL9ynlyw"
      },
      "source": [
        "### Keras 'compile()' - Option II\n",
        "\n",
        "A)  arguments values set by calling **keras functions with default parameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsH6ClxUnlyw"
      },
      "source": [
        "The code below is equivalent to the previous one:\n",
        "\n",
        "###### Observation: in order to compile the model with using the alternative code for the compile function please run again the code that defines the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kUNS7kenlyw"
      },
      "source": [
        "model = Sequential()                           # creates a Sequential model object\n",
        "model.add(Flatten(input_shape=[28, 28]))       # to convert each input image into a 1D array, specify the input_shape because it is the first layer\n",
        "model.add(Dense(300, activation=\"relu\", name = 'first_hidden'))       # Dense hidden layer with 300 neurons, ReLU non-linearity\n",
        "model.add(Dense(10, activation =\"softmax\", name = 'output_layer'))     #  output layer with 10 neurons (one per class)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIrwmzpFnlyw"
      },
      "source": [
        "# equivalently....\n",
        "model.compile(optimizer = tf.keras.optimizers.SGD(),\n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics = [tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw4TTxcinlyx",
        "outputId": "c7349ff5-65fe-4a19-f930-a691ca7c2f25"
      },
      "source": [
        "# running this cell you will train the model for 5 epochs. More explanations are prvided in the section training\n",
        "history = model.fit(x = X_train, y= y_train, epochs = 5, batch_size = 32, validation_data=(X_valid, y_valid) )"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6511 - sparse_categorical_accuracy: 0.8398 - val_loss: 0.3535 - val_sparse_categorical_accuracy: 0.9076\n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3339 - sparse_categorical_accuracy: 0.9080 - val_loss: 0.2843 - val_sparse_categorical_accuracy: 0.9200\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2843 - sparse_categorical_accuracy: 0.9207 - val_loss: 0.2504 - val_sparse_categorical_accuracy: 0.9302\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2540 - sparse_categorical_accuracy: 0.9287 - val_loss: 0.2255 - val_sparse_categorical_accuracy: 0.9394\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2311 - sparse_categorical_accuracy: 0.9353 - val_loss: 0.2100 - val_sparse_categorical_accuracy: 0.9432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy94bRU8nlyx"
      },
      "source": [
        "### Customizing the training process\n",
        "By passing directly the respective **objects** we gain **greater flexibility** as many of these objects\n",
        "themselves have **options** that we might want to have **control** over, as you can see in the the following cell:\n",
        "\n",
        "B)  arguments values set by calling **keras functions and passing in custom values for their parameters**\n",
        "###### Observation: in order to compile the model with using the alternative code for the compile function please run again the code that defines the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxjQqXRqnlyx"
      },
      "source": [
        "model = Sequential()                           # creates a Sequential model object\n",
        "model.add(Flatten(input_shape=[28, 28]))       # to convert each input image into a 1D array, specify the input_shape because it is the first layer\n",
        "model.add(Dense(300, activation=\"relu\", name = 'first_hidden'))       # Dense hidden layer with 300 neurons, ReLU non-linearity\n",
        "model.add(Dense(10, name = 'output_layer'))  "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgKlOsh6nlyx"
      },
      "source": [
        "model.compile(optimizer =tf.keras.optimizers.SGD(learning_rate = 0.001, momentum = 0.9, nesterov =True),\n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits= True),\n",
        "              metrics= [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "             )"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CybfnNwwnlyx"
      },
      "source": [
        "The cell above shows some of the options we ca use to **control the training process:**</br>\n",
        "\n",
        "##### The stochastic gradient descent \n",
        "\n",
        "An important parameter of the **stochastic gradient descent optimization algorithm** is the **learning_rate**. By default, the learning_rate\n",
        "is set to 0.01 but here we creating in the SGD optimizer objects with learning_rate 0 .001. </br>\n",
        "We are also appling momentum with a value of 0.9. By default, the momentum value is 0. </br>\n",
        "And an extra option we can choose to set is whether or not to use nesterov momentum which\n",
        "here is set True. </br>\n",
        "\n",
        "##### The Sparse Categorical Crossentropy function.\n",
        "Here we are setting the option `from_logits=True`. If you are look carefully, you notice that the activation function in the last layer\n",
        "of the network was changed from softmax (in the previous model) to linear. In other words, now, there is no\n",
        "activation function and we could as well have left this argument out as the linear activation is the default. And so the network is now outputting the\n",
        "`logits` which is any real value before it is passed through the activation function. The *from_logits=True option*\n",
        "tells the model that it should take the output of the network. \n",
        "Another consequence is, the loss function itself must handle the squeezing of the output through the softmax function. Mathematically, there's no difference between this and what we had before but this way turns out to be a more numerically stable approach.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXydz9ptnlyy",
        "outputId": "5aa4351d-5cb5-4e6a-ba15-c24261b7a561"
      },
      "source": [
        "# running this cell you will train the compiled model for 5 epochs. More explanations are prvided in the section training\n",
        "history = model.fit(x = X_train, y= y_train, epochs = 5, batch_size = 32, validation_data=(X_valid, y_valid) )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6765 - sparse_categorical_accuracy: 0.8307 - val_loss: 0.3586 - val_sparse_categorical_accuracy: 0.9058\n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3401 - sparse_categorical_accuracy: 0.9050 - val_loss: 0.2870 - val_sparse_categorical_accuracy: 0.9206\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2887 - sparse_categorical_accuracy: 0.9196 - val_loss: 0.2514 - val_sparse_categorical_accuracy: 0.9320\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2571 - sparse_categorical_accuracy: 0.9286 - val_loss: 0.2267 - val_sparse_categorical_accuracy: 0.9394\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2332 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.2100 - val_sparse_categorical_accuracy: 0.9410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86O3noN5nlyy"
      },
      "source": [
        "## Practice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdFsRNaenlyy"
      },
      "source": [
        "### Exercise 1: \n",
        "\n",
        "Consider the final (output) layers. Why are there 10 of them? What would happen if you had a different amount than 10? For example, try training the network with 5\n",
        "\n",
        "You get an error as soon as it finds an unexpected value. Another rule of thumb -- the number of neurons in the last layer should match the number of classes you are classifying for. In this case it's the digits 0-9, so there are 10 of them, hence you should have 10 neurons in your final layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_R5cOaFuO3q"
      },
      "source": [
        "\n",
        "\n",
        "- The reason why there are 10 neurons in the last(output) layer is that there are totally 10 different classes to be classified (from 0 to 9). \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6mkSPQpnlyy"
      },
      "source": [
        "### Exercise 2: \n",
        "\n",
        "Consider the effects of additional layers in the network or of the changing number of neurons in the hidden layers. What will happen if you add another layer between the one with 300 and the final layer with 10. \n",
        "\n",
        "Ans: There isn't a significant impact -- because this is relatively simple data. For far more complex data (like natural images), extra layers are often necessary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrmJo_1Jv7c1"
      },
      "source": [
        "- There is no obvious effect, since MNIST task is quite easy for Neural Network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVVpHWCznlyy"
      },
      "source": [
        "### Exercise 3: \n",
        "\n",
        "Consider the impact of training for more or less epochs. Why do you think that would be the case? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNtA1TM1vysM"
      },
      "source": [
        "- Too many epochs may cause your model to over-fit the training data. It means that the model does not learn the data, it memorizes the data. \n",
        "- But if we train the network with relatively too little epochs, it may lead to underfitting, which means that the model can be further improved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkZgmrj1nlyy"
      },
      "source": [
        "### Exercise 4: \n",
        "\n",
        "Train the model (two different versions) with the default learning rate as introduced at the first version of the 'compile' method and with the learning rate 1e-3 . What difference can you notice in the training process?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiNqhC3NxXQC"
      },
      "source": [
        "- The default learning rate of SGD is 1e-2. The latter version has smaller learning rate. However, it has fewer loss but more acuracy and it converges even faster. That's because with relative smaller learning rate can possibably get more closer to global minimum. "
      ]
    }
  ]
}