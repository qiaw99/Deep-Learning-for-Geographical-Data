{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "03.1 - Creating a sequential model - 副本.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzGGdkzxkZNU"
      },
      "source": [
        "# Exercise 03.1 - Keras Sequential Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5gEMZNpkZNe"
      },
      "source": [
        "Before you can start, you have to find a GPU on the system that is not heavily used by other users. Otherwise you cannot initialize your neural network.\n",
        "\n",
        "\n",
        "**Hint:** the command is **nvidia-smi**, just in case it is displayed above in two lines because of a line break.\n",
        "\n",
        "As a result you get a summary of the GPUs available in the system, their current memory usage (in MiB for megabytes), and their current utilization (in %). There should be six or eight GPUs listed and these are numbered 0 to n-1 (n being the number of GPUs). The GPU numbers (ids) are quite at the beginning of each GPU section and their numbers increase from top to bottom by 1.\n",
        "\n",
        "Find a GPU where the memory usage is low. For this purpose look at the memory usage, which looks something like '365MiB / 16125MiB'. The first value is the already used up memory and the second value is the total memory of the GPU. Look for a GPU where there is a large difference between the first and the second value.\n",
        "\n",
        "**Remember the GPU id and write it in the next line instead of the character X.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-9VGyvykZNh"
      },
      "source": [
        "# Change X to the GPU number you want to use,\n",
        "# otherwise you will get a Python error\n",
        "# e.g. USE_GPU = 4\n",
        "USE_GPU = 1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGxyt_6xkZNj",
        "outputId": "de684104-c1a2-4567-f5d8-373d1bf753cf"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 10 11:30:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkAbjIQckZNk"
      },
      "source": [
        "### Choose one GPU\n",
        "\n",
        "**The following code is very important and must always be executed before using TensorFlow in the exercises, so that only one GPU is used and that it is set in a way that not all its memory is used at once. Otherwise, the other students will not be able to work with this GPU.**\n",
        "\n",
        "The following program code imports the TensorFlow library for Deep Learning and outputs the version of the library.\n",
        "\n",
        "Then, TensorFlow is configured to only see the one GPU whose number you wrote in the above cell (USE_GPU = X) instead of the X.\n",
        "\n",
        "Finally, the GPU is set so that it does not immediately reserve all memory, but only uses more memory when needed. \n",
        "\n",
        "(The comments within the code cell explains a bit of what is happening if you are interested to better understand it. See also the documentation of TensorFlow for an explanation of the used methods.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I68HPUU8kZNl",
        "outputId": "c0ea9d1b-6c6e-471e-ba04-b821c04ab94f"
      },
      "source": [
        "# Import TensorFlow \n",
        "import tensorflow as tf\n",
        "\n",
        "# Print the installed TensorFlow version\n",
        "print(f'TensorFlow version: {tf.__version__}\\n')\n",
        "\n",
        "# Get all GPU devices on this server\n",
        "gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "# Print the name and the type of all GPU devices\n",
        "print('Available GPU Devices:')\n",
        "for gpu in gpu_devices:\n",
        "    print(' ', gpu.name, gpu.device_type)\n",
        "    \n",
        "# Set only the GPU specified as USE_GPU to be visible\n",
        "tf.config.set_visible_devices(gpu_devices[0], 'GPU')\n",
        "\n",
        "# Get all visible GPU  devices on this server\n",
        "visible_devices = tf.config.get_visible_devices('GPU')\n",
        "\n",
        "# Print the name and the type of all visible GPU devices\n",
        "print('\\nVisible GPU Devices:')\n",
        "for gpu in visible_devices:\n",
        "    print(' ', gpu.name, gpu.device_type)\n",
        "    \n",
        "# Set the visible device(s) to not allocate all available memory at once,\n",
        "# but rather let the memory grow whenever needed\n",
        "for gpu in visible_devices:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.7.0\n",
            "\n",
            "Available GPU Devices:\n",
            "  /physical_device:GPU:0 GPU\n",
            "\n",
            "Visible GPU Devices:\n",
            "  /physical_device:GPU:0 GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQGiP7PukZNm"
      },
      "source": [
        "# Introduction to the Keras Sequential Model\n",
        "\n",
        "This notebook is the first part of the tutorial 'Introduction to Keras sequential model' and introduces the possibilities to create a sequential model in keras.\n",
        "\n",
        "#### A typical Keras workflow includes the following steps:\n",
        "\n",
        "-  configurating of the training data: *input tensors* and  *target tensors*   \n",
        "-  defining a stack of layers - `the model`- that will encode the mapping from inputs to the target\n",
        "-  configurate the learning process via the `compile()` function \n",
        "-  train the model on the labeled data by calling the `.fit`method ob the model object\n",
        "-  evaluation of the model on the validation/test data\n",
        "-  prediction on test data\n",
        "\n",
        "Keras provides several possibilities (3 API styles) for creating a deep learning model:\n",
        "\n",
        "- [Sequential API](https://www.tensorflow.org/guide/keras/sequential_model?hl=en) (simple, single -input, single -output, sequential layer stacks)\n",
        "-  [Functional API](https://www.tensorflow.org/guide/keras/functional?hl=en) (multi-input, multi-output, arbitrary static graph configurations)\n",
        "- *Model subclassing* (maximum flexibility, larger potential error surface)\n",
        "\n",
        "In this notebook we will focus on the step of creating a neural network by using the functionality of TF keras Sequential API.\n",
        "\n",
        "## Learning objectives\n",
        "- understand the TF keras Sequential API and TF keras layers API\n",
        "- learn to create a sequential model object \n",
        "- learn different methods to add layers to a model\n",
        "- learn several types of layers implemented in TF keras layer API\n",
        "- learn the required arguments for creating layers\n",
        "- learn how to add non-linearities to the output of a layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBvwxxe1kZNo"
      },
      "source": [
        "### Keras Sequential class\n",
        "\n",
        "In this tutorial, we going to introduce the **keras sequential class**. It is appropriate for building models with simple topology, composed of a stack of layers, where each layer has exactely one input and one output.\n",
        "In fact, you'll find that most of the neural networks that you work with, can be built using the sequential class. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nid_E9nkZNp"
      },
      "source": [
        "##### Imports\n",
        "We will import `sequential class` from `tensorflow.keras.models` and the `dense layer` class from `tensorflow.keras.layers`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRgVygKxkZNq"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import  Flatten, Dense"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO2qmj98kZNr"
      },
      "source": [
        "## Creating a feed forward network (Method 1)\n",
        "\n",
        "In the following example, we will create a model for solving  classification task, where the output can be assigned to one of 10 possible classes (categories).\n",
        "The input to the model are images og size 28 x 28 x 1 pixels. \n",
        "\n",
        "**Sequential**:  Instantiate an `model`object using  [Sequential class](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential) and pass in a **list** of keras **layers** It defines a SEQUENCE of layers in the neural network.\n",
        "\n",
        "The core building block of neural networks is the `layer`, a data-processing module which you can conceive as a \"filter\" for data.  Most of deep learning really consists of chaining together simple layers which will implement a form of progressive \"data distillation\". A deep learning model is like a sieve for data processing, made of a succession of increasingly refined data filters -- the  `layers`.\n",
        "\n",
        "\n",
        "\n",
        "The model will consist of:\n",
        "\n",
        " * 1 reshaping operation\n",
        " * 1 fully connected layer (the hidden layer), containing 64 neurons and has a ReLU activation\n",
        " * 1 fully connected layer (the output layer), containing 10 neurons (the number of classes) and has softmax activation\n",
        "\n",
        "\n",
        "The possible types of layers to build a NN are defined [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers). <br>\n",
        "**Flatten**:  Flatten just takes a multidimensional tensor and turns it into a 1 dimensional set.\n",
        "\n",
        "**Dense**: Adds a layer of neurons. **A fully connected layer** in keras is implemented by the class `tensorflow.keras.layers.Dense`. To instantiate a [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer object we need to pass to the constructor as required key word argument `units` a value for the numbers of neurons in the layer. Aditionally, we have to specify the type of activation e.g. 'relu', per default the activation is `None`, so no non-linearity will be applied unless we specify one.\n",
        "**ReLU** effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n",
        "\n",
        "**Softmax** takes a set of values, and picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it turns it into [0,0,0,0,1,0,0,0,0] \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYMWkeepkZNr"
      },
      "source": [
        "#### Specifying the input shape\n",
        "\n",
        "We specify explicitly the shape of the input data  by passing pass an **input_shape argument** ONLY TO THE  **first layer**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kasFtG1QkZNs"
      },
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape = (28,28)), #(784,)\n",
        "    Dense(units = 64, activation = 'relu'),\n",
        "    Dense(units = 10, activation = 'softmax')\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79wHC1QTkZNt"
      },
      "source": [
        "Here we are specifying that each input data example will be a one-dimensional vector of size 784.\n",
        "Because the input shape is provided, the weights and biases will be created and initialized straight away.\n",
        "##### The usage of a Flatten layer </br>\n",
        "The flatten layer has no parameters and just has the role to unroll a higher dimenssional tensors (e.g. images) to a one dimenssional vector. Commonly is used for feeding a higher dimenssional tensors to a fully connecetd layer (dense layer). </br>\n",
        "Here, we have images/tensors of shape (28,28) which are converted it into a long one-dimensional vector of size 784 before sending it through to the first dense layer. </br>\n",
        "To check the existence of the weights and biases you can call the attribute `weights` on the object` model` or the method summary() as in the following cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrfFoR_kkZNu"
      },
      "source": [
        "# model.weights"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5CGOIr3kZNv",
        "outputId": "fb885014-7f29-40a9-9b23-7fdb82276827"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oYkqni2kZNw"
      },
      "source": [
        "## Creating a feed forward network (Method 2)\n",
        "\n",
        "Instead of passing in a list of layers, you can call the `.add()` method on the created model instance to append additional layers to the model.\n",
        "The model in the following cell is an equivalent model to the one we build before.\n",
        "This method is useful for adding layers one at a time, when building code to depend on some conditions or loops."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0uOAkgxkZNw"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape = (28,28)))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(units = 10, activation = 'softmax'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaqBadMCkZNx",
        "outputId": "5d052724-90be-46aa-b6f1-7f655231234c"
      },
      "source": [
        "model.count_params()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50890"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTJ79k_2kZNx",
        "outputId": "21e9540f-99db-4374-bff5-2d9d47c6de20"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDmSy7j7kZNy"
      },
      "source": [
        "You'll notice that the first dimension of every tensor has a value `None`. And that's because the first dimension will always be the `batch size`. Because we can feed any number of training examples when training the model, the batch_size is unknown at this moment (flexible). Tensorflow represents this with the value `None` in the tensor shape. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw0c18b9kZNy"
      },
      "source": [
        "#### Observation:\n",
        "We specifed the activation as readable strings, e.g, 'relu', 'softmax'. However, these redeadable strings are references   TF objects or functions: [tf.keras.layers.ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU) and \n",
        " [tf.keras.layers.softmax](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Softmax)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbttfakrkZNz"
      },
      "source": [
        "#### Exercise: Exploring the Sequential model\n",
        "\n",
        "    1) You can substitute the Softmax activation function in the last dense layer with a new Softmax layer. Run run `model.summary`, to check that the output is identical as the previous one.\n",
        "    2 ) In addition, you can try to define a name for each layer by providing a string value to the kew-word argument `name` when creating a new layer e.g. name = 'first_layer'\n",
        "    3) Change the activations of the dense layers to hyperbolic tangent or the sigmoid function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkmhnrEQkZN0"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape = (28,28)))\n",
        "model.add(Dense(64, activation = 'tanh', name=\"first_layer\"))\n",
        "model.add(Dense(10, activation='tanh', name=\"second_layer\"))\n",
        "model.add(tf.keras.layers.Softmax())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3bOMWAZmtZN",
        "outputId": "9b3e3e47-0b88-4d41-cba2-8077e900ebba"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " first_layer (Dense)         (None, 64)                50240     \n",
            "                                                                 \n",
            " second_layer (Dense)        (None, 10)                650       \n",
            "                                                                 \n",
            " softmax (Softmax)           (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}