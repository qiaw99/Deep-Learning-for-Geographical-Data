{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 - PointNet++ Feature Propagation Layer (Code Study)\n",
    "\n",
    "This notebook is a detailed code study of the PointNet++ Feature Propagation (FP) layer.\n",
    "\n",
    "It is based on the Keras layer implememtation of PointNet++ from https://github.com/dgriffiths3/pointnet2-tensorflow2.\n",
    "\n",
    "Follow the notebook to better understand the Feature Propagation layer and its implementation. It is assumed that you already completed the code study of the Set Abstraction layer. Therefore, repeated sections are not explained once more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change X to the GPU number you want to use,\n",
    "# otherwise you will get a Python error\n",
    "# e.g. USE_GPU = 4\n",
    "USE_GPU = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.3.1\n",
      "\n",
      "Available GPU Devices:\n",
      "  /physical_device:GPU:0 GPU\n",
      "  /physical_device:GPU:1 GPU\n",
      "  /physical_device:GPU:2 GPU\n",
      "  /physical_device:GPU:3 GPU\n",
      "  /physical_device:GPU:4 GPU\n",
      "  /physical_device:GPU:5 GPU\n",
      "  /physical_device:GPU:6 GPU\n",
      "  /physical_device:GPU:7 GPU\n",
      "\n",
      "Visible GPU Devices:\n",
      "  /physical_device:GPU:4 GPU\n",
      "\n",
      "Keras version: 2.4.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow \n",
    "import tensorflow as tf\n",
    "\n",
    "# Print the installed TensorFlow version\n",
    "print(f'TensorFlow version: {tf.__version__}\\n')\n",
    "\n",
    "# Get all GPU devices on this server\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Print the name and the type of all GPU devices\n",
    "print('Available GPU Devices:')\n",
    "for gpu in gpu_devices:\n",
    "    print(' ', gpu.name, gpu.device_type)\n",
    "    \n",
    "# Set only the GPU specified as USE_GPU to be visible\n",
    "tf.config.set_visible_devices(gpu_devices[USE_GPU], 'GPU')\n",
    "\n",
    "# Get all visible GPU  devices on this server\n",
    "visible_devices = tf.config.get_visible_devices('GPU')\n",
    "\n",
    "# Print the name and the type of all visible GPU devices\n",
    "print('\\nVisible GPU Devices:')\n",
    "for gpu in visible_devices:\n",
    "    print(' ', gpu.name, gpu.device_type)\n",
    "    \n",
    "# Set the visible device(s) to not allocate all available memory at once,\n",
    "# but rather let the memory grow whenever needed\n",
    "for gpu in visible_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "# Import Keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# Print the installed Keras version\n",
    "print(f'\\nKeras version: {keras.__version__}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare TensorFlow CUDA operations\n",
    "\n",
    "In this section, the TensorFlow operations implemented in CUDA (a programming language for GPUs from NVIDIA) are prepared to be used in the PointNet++ Jupyter notebooks.\n",
    "\n",
    "**Note that this section of the notebook needs only be executed once to install and compile the TensorFlow CUDA operations.** But there should be no harm in executing it repeatedly. \n",
    "\n",
    "**Make sure that the file 'tf_ops.zip' is in the same folder as this notebook and all other notebooks you want to use these TensorFlow operations with.**\n",
    "\n",
    "The following is commented out, assuming you already did this. If not, then uncomment and execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip -o -q \"tf_ops.zip\"\n",
    "\n",
    "#!chmod u+x \"tf_ops/compile_ops.sh\"\n",
    "\n",
    "#!tf_ops/compile_ops.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a point cloud patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# directory of PointNet data\n",
    "data_dir = str(Path.home()) + r'/coursematerial/GIS/ISPRS/PointNet++'\n",
    "\n",
    "# filename and path of one patch\n",
    "filename = r'Vaihingen3D_Training_0016.csv'\n",
    "filepath = os.path.join(data_dir, 'patches', filename)\n",
    "\n",
    "# read csv file as Pandas DataFrame\n",
    "xyz_df = pd.read_csv(filepath, sep=' ')\n",
    "\n",
    "# extract x,y,z-columns from DataFrame and convert to NumPy array\n",
    "xyz = xyz_df[['x','y','z']].to_numpy()\n",
    "\n",
    "# center by center point of bounding box\n",
    "min = np.min(xyz, axis=0)\n",
    "max = np.max(xyz, axis=0)\n",
    "xyz = xyz - np.expand_dims(0.5 * (max+min), axis=0)\n",
    "\n",
    "# extract the labels from DataFrame\n",
    "labels = xyz_df[['labels']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100000, 3), dtype=float32, numpy=\n",
       "array([[[ 1.0000e-02, -8.5000e-02, -1.8950e+00],\n",
       "        [ 1.0000e-02,  1.8500e-01, -1.8450e+00],\n",
       "        [ 1.0000e-02,  1.9500e-01, -1.8350e+00],\n",
       "        ...,\n",
       "        [ 4.4900e+01, -3.2345e+01, -4.9250e+00],\n",
       "        [-5.2490e+01, -1.7135e+01, -3.6250e+00],\n",
       "        [-5.2490e+01, -1.7135e+01, -3.6250e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz = tf.convert_to_tensor(np.expand_dims(xyz, axis=0), dtype=tf.float32)\n",
    "\n",
    "xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract 4k & 1K points\n",
    "\n",
    "The Feature Propagation layer takes two point sets as input, one with fewer points and one with more points. We therefore use farthest point sampling to sample first a tensor of 4096 points with xyz-coordinates and from this one another tensor of 1024 points with xyz-coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tf operations\n",
    "from tf_ops.tf_ops import (\n",
    "    farthest_point_sample,\n",
    "    three_nn,\n",
    "    three_interpolate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096, 3)\n",
      "(1, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "xyz4096 = tf.gather(xyz, farthest_point_sample(4096, xyz), axis=1, batch_dims=1)\n",
    "print(xyz4096.shape)\n",
    "\n",
    "xyz1024 = tf.gather(xyz4096, farthest_point_sample(1024, xyz4096), axis=1, batch_dims=1)\n",
    "print(xyz1024.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And construct some feature tensors of random values with 5 and 8 channels. The point set with fewer points has more features. (Typically many more than just 5 and 8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea4096 = tf.random.uniform(shape=[1, 4096, 5])\n",
    "fea1024 = tf.random.uniform(shape=[1, 1024, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indices of 3 nearest neighbors\n",
    "\n",
    "As we want to propagate the features from the point set with fewer points to the point set with more points, we have to identify the points from which to take the features as input.\n",
    "\n",
    "The function **three_nn()** determines for each point of the set of 4096 points the indices of the 3 nearest neighbor points of the set containing 1024 points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096, 3)\n",
      "(1, 4096, 3)\n"
     ]
    }
   ],
   "source": [
    "dist, idx = three_nn(xyz4096, xyz1024)\n",
    "print(dist.shape)\n",
    "print(idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([  0, 944, 732], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 indices of first point (of first batch)\n",
    "idx[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the point includes itself as one of the 3 nearest neighbors. Points like this are points that are in both sets. (Which is not surprising for the first point, as the first point is always sampled in farthest point sampling.) Therefore, we choose another point at index 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([521, 419, 205], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 indices of 2006th point (of first batch)\n",
    "idx[0, 2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 6.4746046,  8.125095 , 13.816187 ], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[0, 2005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights for inverse distance weighting (IDW)\n",
    "\n",
    "We now calculate the weights for the inverse distance weighting. This is a vector implementation that calculates the weights for the complete set of 4096 points. (If you do not know inverse distance weighting, then please check https://en.wikipedia.org/wiki/Inverse_distance_weighting. The idea is basically that the weights are inversely proportional to the distances, where the weights must sum up to 1. Therefore, the weights are normalized, here by dividing by norm.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096, 3)\n"
     ]
    }
   ],
   "source": [
    "# make sure there is no distance of 0.0, as we need to divide by the distance\n",
    "dist = tf.maximum(dist, 1e-10)\n",
    "\n",
    "# sum the 3 distances per point\n",
    "norm = tf.reduce_sum((1.0/dist),axis=2, keepdims=True)\n",
    "\n",
    "# repeat the sum for all three distances\n",
    "norm = tf.tile(norm,[1,1,3])\n",
    "\n",
    "# divide and normalize\n",
    "weight = (1.0/dist) / norm\n",
    "\n",
    "print(weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights for points that are in both sets (4096 and 1024) is calculated as 1.0, so that it keeps its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.000000e+00, 9.407515e-12, 6.689276e-12], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all other points, the weights are a combination of the 3 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.44140565, 0.35174075, 0.20685355], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight[0, 2005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate with IDW\n",
    "\n",
    "Using the indices and the calculated weights, the CUDA operation **three_interpolate()** performs the interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096, 8)\n"
     ]
    }
   ],
   "source": [
    "interpolated_points = three_interpolate(fea1024, idx, weight)\n",
    "print(interpolated_points.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you notice from the outputs of the following cell, the features of the first point that appears in both point sets keep their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.05276966 0.41259992 0.96929705 0.8000699  0.45917094 0.20513296\n",
      " 0.70916283 0.562122  ], shape=(8,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.05276966 0.41259992 0.96929705 0.8000699  0.45917094 0.20513296\n",
      " 0.70916283 0.562122  ], shape=(8,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(fea1024[0, 0])\n",
    "print(interpolated_points[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the feature values of the point at index 2005 is the interpolation of the 3 nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors:\n",
      "tf.Tensor(\n",
      "[0.6469661  0.7789264  0.5930282  0.7617823  0.90258455 0.23327053\n",
      " 0.1712929  0.04030871], shape=(8,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.04414821 0.85745466 0.39262962 0.39014578 0.70860076 0.2864374\n",
      " 0.43942547 0.33796513], shape=(8,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.43107855 0.53848195 0.6230464  0.5000411  0.9263269  0.6379752\n",
      " 0.6030979  0.40158522], shape=(8,), dtype=float32)\n",
      "\n",
      "Weights:\n",
      "tf.Tensor([0.44140565 0.35174075 0.20685355], shape=(3,), dtype=float32)\n",
      "\n",
      "Interpolated tensor:\n",
      "tf.Tensor(\n",
      "[0.39027336 0.75681114 0.5287492  0.57692045 0.8392637  0.3356861\n",
      " 0.35492644 0.21973795], shape=(8,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('Input tensors:')\n",
    "print(fea1024[0, idx[0, 2005, 0]])\n",
    "print(fea1024[0, idx[0, 2005, 1]])\n",
    "print(fea1024[0, idx[0, 2005, 2]])\n",
    "\n",
    "print('\\nWeights:')\n",
    "print(weight[0, 2005])\n",
    "\n",
    "print('\\nInterpolated tensor:')\n",
    "print(interpolated_points[0, 2005])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine features from both layers\n",
    "\n",
    "At the end, the interpolated features and point features (that are with the 4096 points from the set abstraction layer) are concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096, 13)\n"
     ]
    }
   ],
   "source": [
    "new_fea4096 = tf.concat(axis=2, values=[interpolated_points, fea4096]) # B,ndataset1,nchannel1+nchannel2\n",
    "print(new_fea4096.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer perceptron\n",
    "\n",
    "What follows in the Feature Propagation layer is the multi-layer perceptron that is applied on the concatenated features.\n",
    "\n",
    "Because the 2D convolutional layers require 4D tensors, the dimension of the feature tensor needs to be expanded first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096, 1, 13)\n"
     ]
    }
   ],
   "source": [
    "new_fea4096_xdim = tf.expand_dims(new_fea4096, 2)\n",
    "print(new_fea4096_xdim.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the concatenated feature tensor goes through a multi-layer perceptron. As we do not have a trained MLP in this notebook, the following cell is commented out.\n",
    "\n",
    "The list mlp_list contains 2D convolutional layers. The for-loop iterates over all these layers, and applies the tensor to every layer. The resulting tensor has the same dimensions with the exception of the last dimension, which has as many channels as the last convolutional layer has filters.\n",
    "\n",
    "We just generate a tensor with random values with an appropriate shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "#for i, mlp_layer in enumerate(self.mlp_list):\n",
    "#    new_points1 = mlp_layer(new_points1, training=training)\n",
    "\n",
    "mlp_output = tf.random.uniform(shape=[1, 4096, 1, 128])\n",
    "\n",
    "print(mlp_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape output tensor\n",
    "\n",
    "The following cell first gets rid of the dimensions with size 1 and re-introduced a batch dimension (at axis 0) once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squeezed: (4096, 128)\n",
      "Expanded: (1, 4096, 128)\n"
     ]
    }
   ],
   "source": [
    "mlp_output_reshaped = tf.squeeze(mlp_output)\n",
    "print('Squeezed:', mlp_output_reshaped.shape)\n",
    "\n",
    "if len(mlp_output_reshaped.shape) < 3:\n",
    "    mlp_output_reshaped = tf.expand_dims(mlp_output_reshaped, axis=0)\n",
    "\n",
    "print('Expanded:', mlp_output_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Propagation (FP) layer\n",
    "\n",
    "In the following, a (simplified) implementation of the Feature Propagation layer is given as a TensorFlow custom layer.\n",
    "\n",
    "It follows to a large extent what is discussed above. There is some code at the beginning of **call()** that makes sure that the dimensions of the input features are as expected and expands them if they are not.\n",
    "\n",
    "Note the following parameters:\n",
    "\n",
    "- xyz1 is the re-introduced point set (skip connection)\n",
    "- xyz2 is the point set from the previous layer\n",
    "- points1 are the features associated with xyz1\n",
    "- points2 are the features associated with xyz2\n",
    "\n",
    "Note that the feature tensor of the point set with the target points might be empty for the last feature propagation layer, since this is the layer that gets the points from the first set abstraction layer (via skip connection). If the network did not receive any input features, then the skip connections does not provide any features as well. Therefore, points1 could be None and the layer must handle this case by not concatenating points1 with the interpolated points. Then the output is just the interpolated point features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class Pointnet_FP(Layer):\n",
    "\n",
    "    def __init__(self, mlp):\n",
    "        super(Pointnet_FP, self).__init__()\n",
    "\n",
    "        self.mlp = mlp\n",
    "        self.mlp_list = []\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        for i, n_filters in enumerate(self.mlp):\n",
    "            self.mlp_list.append(keras.layers.Conv2D(n_filters, kernel_size=[1,1], activation='relu'))\n",
    "\n",
    "        super(Pointnet_FP, self).build(input_shape)\n",
    "\n",
    "    def call(self, xyz1, xyz2, points1, points2, training=True):\n",
    "\n",
    "        if points1 is not None:\n",
    "            if len(points1.shape) < 3:\n",
    "                points1 = tf.expand_dims(points1, axis=0)\n",
    "        if points2 is not None:\n",
    "            if len(points2.shape) < 3:\n",
    "                points2 = tf.expand_dims(points2, axis=0)\n",
    "\n",
    "        dist, idx = three_nn(xyz1, xyz2)\n",
    "        dist = tf.maximum(dist, 1e-10)\n",
    "        norm = tf.reduce_sum((1.0/dist),axis=2, keepdims=True)\n",
    "        norm = tf.tile(norm,[1,1,3])\n",
    "        weight = (1.0/dist) / norm\n",
    "        interpolated_points = three_interpolate(points2, idx, weight)\n",
    "\n",
    "        if points1 is not None:\n",
    "            new_points1 = tf.concat(axis=2, values=[interpolated_points, points1]) # B,ndataset1,nchannel1+nchannel2\n",
    "        else:\n",
    "            new_points1 = interpolated_points\n",
    "        new_points1 = tf.expand_dims(new_points1, 2)\n",
    "\n",
    "        for i, mlp_layer in enumerate(self.mlp_list):\n",
    "            new_points1 = mlp_layer(new_points1, training=training)\n",
    "\n",
    "        new_points1 = tf.squeeze(new_points1)\n",
    "        if len(new_points1.shape) < 3:\n",
    "            new_points1 = tf.expand_dims(new_points1, axis=0)\n",
    "\n",
    "        return new_points1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please continue with the PointNet++ exercise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}