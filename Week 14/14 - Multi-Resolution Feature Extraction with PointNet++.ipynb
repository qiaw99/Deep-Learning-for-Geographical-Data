{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 14 - Multi-Resolution Feature Extraction with PointNet++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows training and prediction of PointNet++ for aerial point clouds. Its implementation is a simplified version based on the implementation of Keras layers that can be found on https://github.com/dgriffiths3/pointnet2-tensorflow2. This notebook is rather rough with few comments, as most was already explained in previous notebooks and the code studies of the PointNet++ layers provided in additional notebooks.\n",
    "\n",
    "There are no active tasks for this course topic, just a demonstration to study, train, and do some predictions with PointNet++."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup TensorFLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change X to the GPU number you want to use,\n",
    "# otherwise you will get a Python error\n",
    "# e.g. USE_GPU = 4\n",
    "USE_GPU = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.3.1\n",
      "\n",
      "Available GPU Devices:\n",
      "  /physical_device:GPU:0 GPU\n",
      "  /physical_device:GPU:1 GPU\n",
      "  /physical_device:GPU:2 GPU\n",
      "  /physical_device:GPU:3 GPU\n",
      "  /physical_device:GPU:4 GPU\n",
      "  /physical_device:GPU:5 GPU\n",
      "  /physical_device:GPU:6 GPU\n",
      "  /physical_device:GPU:7 GPU\n",
      "\n",
      "Visible GPU Devices:\n",
      "  /physical_device:GPU:4 GPU\n",
      "\n",
      "Keras version: 2.4.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow \n",
    "import tensorflow as tf\n",
    "\n",
    "# Print the installed TensorFlow version\n",
    "print(f'TensorFlow version: {tf.__version__}\\n')\n",
    "\n",
    "# Get all GPU devices on this server\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Print the name and the type of all GPU devices\n",
    "print('Available GPU Devices:')\n",
    "for gpu in gpu_devices:\n",
    "    print(' ', gpu.name, gpu.device_type)\n",
    "    \n",
    "# Set only the GPU specified as USE_GPU to be visible\n",
    "tf.config.set_visible_devices(gpu_devices[USE_GPU], 'GPU')\n",
    "\n",
    "# Get all visible GPU  devices on this server\n",
    "visible_devices = tf.config.get_visible_devices('GPU')\n",
    "\n",
    "# Print the name and the type of all visible GPU devices\n",
    "print('\\nVisible GPU Devices:')\n",
    "for gpu in visible_devices:\n",
    "    print(' ', gpu.name, gpu.device_type)\n",
    "    \n",
    "# Set the visible device(s) to not allocate all available memory at once,\n",
    "# but rather let the memory grow whenever needed\n",
    "for gpu in visible_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "# Import Keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# Print the installed Keras version\n",
    "print(f'\\nKeras version: {keras.__version__}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare TensorFlow CUDA operations\n",
    "\n",
    "In this section, the TensorFlow operations implemented in CUDA (a programming language for GPUs from NVIDIA) are prepared to be used in the PointNet++ Jupyter notebooks.\n",
    "\n",
    "**Note that this section of the notebook needs only be executed once to install and compile the TensorFlow CUDA operations.** But there should be no harm in executing it repeatedly. \n",
    "\n",
    "**Make sure that the file 'tf_ops.zip' is in the same folder as this notebook and all other notebooks you want to use these TensorFlow operations with.**\n",
    "\n",
    "The following is commented out, assuming you already did this. If not, then uncomment and execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip -o -q \"tf_ops.zip\"\n",
    "\n",
    "#!chmod u+x \"tf_ops/compile_ops.sh\"\n",
    "\n",
    "#!tf_ops/compile_ops.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following helper function loads point cloud patches from csv files according to filenames with wildcards (*) from the same directory as Numpy arrays. For evaluation, there are also patches where the point indices are stored, so that the points in these patches can be matched again for a complete point cloud. If data_augmentation is True, then the patches are repeated and rotated by 10 different degrees. The dataset increases by a factor of 10, which results in much longer training times. But data augmentation also increases the accuracy by a few percent (maybe 2-3%). (If you compare it with a trained network without data augmentation, then you have to make sure you train with approximately the same number of batches, as one epoch with data augmentation is 10  times as large as one without.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def load_data_from_csv(filepath, indices=False, data_augmentation=False):\n",
    "        \n",
    "    xyz_list = []\n",
    "    feature_list = []\n",
    "    labels_list = []\n",
    "    indices_list = []\n",
    "    \n",
    "    for file in glob.glob(filepath):\n",
    "        \n",
    "        if indices:\n",
    "            df = pd.read_csv(file, sep=' ', index_col=0)        \n",
    "        else:\n",
    "            df = pd.read_csv(file, sep=' ')        \n",
    "            \n",
    "        xyz = df[['x', 'y', 'z']].to_numpy()\n",
    "       \n",
    "        # make it vector based - START\n",
    "        xmin = np.min(df['x'])\n",
    "        xmax = np.max(df['x'])\n",
    "        ymin = np.min(df['y'])\n",
    "        ymax = np.max(df['y'])\n",
    "        zmin = np.min(df['z'])\n",
    "        zmax = np.max(df['z'])\n",
    "                  \n",
    "        # center by center point \n",
    "        xyz = xyz - np.array([0.5 * (xmax+xmin), 0.5 * (ymax+ymin), 0.5 * (zmax+zmin)])   \n",
    "        \n",
    "        xyz_list.append(xyz)\n",
    "        feature_list.append(df[['intensity', 'return_number', 'number_of_returns']].to_numpy(dtype=float))\n",
    "        labels_list.append(df['labels'].to_numpy())\n",
    "        \n",
    "        if indices:\n",
    "            indices_list.append(df.index.to_numpy())\n",
    "        \n",
    "    xyz = np.stack(xyz_list)\n",
    "    features = np.stack(feature_list)\n",
    "    labels = np.stack(labels_list)\n",
    "    \n",
    "    if indices:\n",
    "        idx = np.stack(indices_list)\n",
    "    \n",
    "    # rotate patches by their center point as data augmentation\n",
    "    if data_augmentation:\n",
    "                \n",
    "        mat_list = []\n",
    "\n",
    "        for i in range(0, 360, 36):\n",
    "            rad = float(i) * np.pi / 180.0\n",
    "            sin = np.sin(rad)\n",
    "            cos = np.cos(rad)\n",
    "            rot_mat = np.array([[cos, -sin, 0.0], [sin, cos, 0.0], [0.0, 0.0, 1.0]])\n",
    "            mat_list.append(rot_mat)\n",
    "\n",
    "        mat = np.stack(mat_list)\n",
    "        mat.shape\n",
    "\n",
    "        xyz = np.reshape(np.reshape(xyz, (-1, 3)) @ mat, (-1, 100000, 3))\n",
    "        labels = np.tile(labels, (len(mat_list), 1))\n",
    "        features = np.tile(features, (len(mat_list), 1, 1))\n",
    "    \n",
    "    xyz = np.concatenate((xyz, features), axis=-1)\n",
    "    \n",
    "    if indices:\n",
    "        return xyz, labels[:, :, np.newaxis], idx\n",
    "    else:\n",
    "        return xyz, labels[:, :, np.newaxis]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ISPRS training patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (420, 100000, 6)\n",
      "y: (420, 100000, 1)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "data_dir = str(Path.home()) + r'/coursematerial/GIS/ISPRS/PointNet++'\n",
    " \n",
    "xyz, labels = load_data_from_csv(os.path.join(data_dir, 'patches', 'Vaihingen3D_Training*.csv'), data_augmentation=True)\n",
    "    \n",
    "print('X:', xyz.shape)\n",
    "print('y:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom SA and FP Keras Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, custom Keras layers for TensorFlow are implemented for the set abstraction layer and the feature propagation layer. \n",
    "\n",
    "**For an in-depth explanation of the implementation of the two layers, please refer to the respective code study notebooks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_ops.tf_ops import (\n",
    "    farthest_point_sample,\n",
    "    gather_point,\n",
    "    query_ball_point,\n",
    "    group_point,\n",
    "    knn_point,\n",
    "    three_nn,\n",
    "    three_interpolate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_group(npoint, radius, nsample, xyz, points, knn=False, use_xyz=True):\n",
    "\n",
    "    new_xyz = gather_point(xyz, farthest_point_sample(npoint, xyz)) # (batch_size, npoint, 3)\n",
    "\n",
    "    if knn:\n",
    "        _,idx = knn_point(nsample, xyz, new_xyz)\n",
    "    else:\n",
    "        idx, pts_cnt = query_ball_point(radius, nsample, xyz, new_xyz)\n",
    "    grouped_xyz = group_point(xyz, idx) # (batch_size, npoint, nsample, 3)\n",
    "    grouped_xyz -= tf.tile(tf.expand_dims(new_xyz, 2), [1,1,nsample,1]) # translation normalization\n",
    "    if points is not None:\n",
    "        grouped_points = group_point(points, idx) # (batch_size, npoint, nsample, channel)\n",
    "        if use_xyz:\n",
    "            new_points = tf.concat([grouped_xyz, grouped_points], axis=-1) # (batch_size, npoint, nample, 3+channel)\n",
    "        else:\n",
    "            new_points = grouped_points\n",
    "    else:\n",
    "        new_points = grouped_xyz\n",
    "\n",
    "    return new_xyz, new_points, idx, grouped_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class Pointnet_SA(Layer):\n",
    "\n",
    "    def __init__(\n",
    "        self, npoint, radius, nsample, mlp, knn=False, use_xyz=True):\n",
    "\n",
    "        super(Pointnet_SA, self).__init__()\n",
    "\n",
    "        self.npoint = npoint\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        self.mlp = mlp\n",
    "        self.knn = False\n",
    "        self.use_xyz = use_xyz\n",
    "\n",
    "        self.mlp_list = []\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "\n",
    "        for i, n_filters in enumerate(self.mlp):\n",
    "            self.mlp_list.append(keras.layers.Conv2D(n_filters, kernel_size=[1,1], activation='relu'))\n",
    "\n",
    "        super(Pointnet_SA, self).build(input_shape)\n",
    "\n",
    "    def call(self, xyz, points, training=True):\n",
    "\n",
    "        if points is not None:\n",
    "            if len(points.shape) < 3:\n",
    "                points = tf.expand_dims(points, axis=0)\n",
    "\n",
    "        new_xyz, new_points, idx, grouped_xyz = sample_and_group(\n",
    "            self.npoint, self.radius, self.nsample, xyz, points, False, use_xyz=True)\n",
    "\n",
    "        for i, mlp_layer in enumerate(self.mlp_list):\n",
    "            new_points = mlp_layer(new_points, training=training)\n",
    "\n",
    "        new_points = tf.math.reduce_max(new_points, axis=2, keepdims=True)\n",
    "\n",
    "        return new_xyz, tf.squeeze(new_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pointnet_FP(Layer):\n",
    "\n",
    "    def __init__(self, mlp):\n",
    "\n",
    "        super(Pointnet_FP, self).__init__()\n",
    "\n",
    "        self.mlp = mlp\n",
    "        self.mlp_list = []\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        for i, n_filters in enumerate(self.mlp):\n",
    "            self.mlp_list.append(keras.layers.Conv2D(n_filters, kernel_size=[1,1], activation='relu'))\n",
    "\n",
    "        super(Pointnet_FP, self).build(input_shape)\n",
    "\n",
    "    def call(self, xyz1, xyz2, points1, points2, training=True):\n",
    "\n",
    "        if points1 is not None:\n",
    "            if len(points1.shape) < 3:\n",
    "                points1 = tf.expand_dims(points1, axis=0)\n",
    "        if points2 is not None:\n",
    "            if len(points2.shape) < 3:\n",
    "                points2 = tf.expand_dims(points2, axis=0)\n",
    "\n",
    "        dist, idx = three_nn(xyz1, xyz2)\n",
    "        dist = tf.maximum(dist, 1e-10)\n",
    "        norm = tf.reduce_sum((1.0/dist),axis=2, keepdims=True)\n",
    "        norm = tf.tile(norm,[1,1,3])\n",
    "        weight = (1.0/dist) / norm\n",
    "        interpolated_points = three_interpolate(points2, idx, weight)\n",
    "\n",
    "        if points1 is not None:\n",
    "            new_points1 = tf.concat(axis=2, values=[interpolated_points, points1]) # B,ndataset1,nchannel1+nchannel2\n",
    "        else:\n",
    "            new_points1 = interpolated_points\n",
    "        new_points1 = tf.expand_dims(new_points1, 2)\n",
    "\n",
    "        for i, mlp_layer in enumerate(self.mlp_list):\n",
    "            new_points1 = mlp_layer(new_points1, training=training)\n",
    "\n",
    "        new_points1 = tf.squeeze(new_points1)\n",
    "        if len(new_points1.shape) < 3:\n",
    "            new_points1 = tf.expand_dims(new_points1, axis=0)\n",
    "\n",
    "        return new_points1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom PointNet++ Model\n",
    "\n",
    "Unfortunately, we cannot provide a detailed explanation of custom layers and models. But most of the code should already be clear or you can guess what is happening.\n",
    "\n",
    "The neural network model with its layers is defined in **init_network()**, and **forward_pass()** is called in training and prediction, where the layers are called like in a functional model.\n",
    "\n",
    "The hyperparameters (number of layers, samples points, radius, etc.) are empirically determined and follow rather common values used in aerial point cloud classification.\n",
    "\n",
    "In this implementation, we also use the additional point cloud features like intensity, return number, etc. that are fed as features into the model (see l0_points that are input to the first SA layer and the last FP layer).\n",
    "\n",
    "What is maybe unusual and unexpected is the use of dense layers after the feature propagation layers. As explained in the lecture, the class scores are the result form a multi-layer perceptron with shared weights that follows the last feature propagation layer. This multi-layer perceptron is applied on each point, and one would very likely expect a 2D convolutional layer. The explanation is simple: because the input tensor of the dense layer has more than 2 dimensions, the dense layer operates along the last axis, meaning it is executed as many times as there are elements in the second to last dimension, and performs the linear combination on the last dimension. You can verify the dimensions by uncommenting the print() method and build the model. It is basically a shared weight implementation of the multi-layer perceptron. Something that is often implemented by a convolutional layer.\n",
    "\n",
    "As an addition side note that is worth mentioning: if the input tensor of a dense layer has too many dimensions, meaning it is not flattened, then the dense layer might not perform the operation that you might expect. Verify this by outputting the shape of the tensor that the dense layer produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "class PointNet4ALSModel(Model):\n",
    "\n",
    "    def __init__(self, batch_size, num_classes):\n",
    "        \n",
    "        super(PointNet4ALSModel, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.keep_prob = 0.5\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.init_network()\n",
    "\n",
    "\n",
    "    def init_network(self):\n",
    "         \n",
    "        self.sa_1 = Pointnet_SA(npoint=8192, radius= 1.0, nsample=16, mlp=[64, 64, 128])\n",
    "        self.sa_2 = Pointnet_SA(npoint=4096, radius= 5.0, nsample=64, mlp=[128, 128, 256])\n",
    "        self.sa_3 = Pointnet_SA(npoint=2048, radius=15.0, nsample=64, mlp=[128, 128, 256])\n",
    "\n",
    "        self.fp_1 = Pointnet_FP(mlp = [256, 256])\n",
    "        self.fp_2 = Pointnet_FP(mlp = [256, 256])\n",
    "        self.fp_3 = Pointnet_FP(mlp = [128, 64])\n",
    "        \n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.dropout1 = Dropout(self.keep_prob)\n",
    "\n",
    "        self.dense2 = Dense(self.num_classes, activation=tf.nn.softmax)\n",
    "                    \n",
    "    def forward_pass(self, input, training):\n",
    "\n",
    "        # split the training data in xyz and features\n",
    "        ln_xyz  = tf.slice(input, [0, 0, 0], [-1, -1,  3])    # point coordinates\n",
    "        ln_feat = tf.slice(input, [0, 0, 3], [-1, -1, -1])    # point attributes\n",
    "                \n",
    "        l0_xyz = ln_xyz\n",
    "        l0_points = ln_feat\n",
    "    \n",
    "        l1_xyz, l1_points = self.sa_1(l0_xyz, l0_points, training=training)\n",
    "        l2_xyz, l2_points = self.sa_2(l1_xyz, l1_points, training=training)\n",
    "        l3_xyz, l3_points = self.sa_3(l2_xyz, l2_points, training=training)\n",
    "\n",
    "        l2_points = self.fp_1(l2_xyz, l3_xyz, l2_points, l3_points, training=training)\n",
    "        l1_points = self.fp_2(l1_xyz, l2_xyz, l1_points, l2_points, training=training)\n",
    "        l0_points = self.fp_3(l0_xyz, l1_xyz, l0_points, l1_points, training=training)\n",
    "\n",
    "        # see explanation of why there is a dense layer here\n",
    "#        print('Shape of input to dense layer:', l0_points.shape, '\\n')\n",
    "        \n",
    "        net = self.dense1(l0_points)\n",
    "        net = self.dropout1(net)\n",
    "        pred = self.dense2(net)\n",
    "                \n",
    "        return pred\n",
    "\n",
    "    def train_step(self, input):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self.forward_pass(input[0], True)\n",
    "            loss = self.compiled_loss(input[1], pred)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        self.compiled_metrics.update_state(input[1], pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "    def test_step(self, input):\n",
    "               \n",
    "        pred = self.forward_pass(input[0], False)\n",
    "        loss = self.compiled_loss(input[1], pred)\n",
    "\n",
    "        self.compiled_metrics.update_state(input[1], pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "    def call(self, input, training=False):\n",
    "\n",
    "        return self.forward_pass(input, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input to dense layer: (1, 100000, 64) \n",
      "\n",
      "Model: \"point_net4als_model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pointnet_sa_12 (Pointnet_SA) multiple                  12928     \n",
      "_________________________________________________________________\n",
      "pointnet_sa_13 (Pointnet_SA) multiple                  66432     \n",
      "_________________________________________________________________\n",
      "pointnet_sa_14 (Pointnet_SA) multiple                  82816     \n",
      "_________________________________________________________________\n",
      "pointnet_fp_12 (Pointnet_FP) multiple                  197120    \n",
      "_________________________________________________________________\n",
      "pointnet_fp_13 (Pointnet_FP) multiple                  164352    \n",
      "_________________________________________________________________\n",
      "pointnet_fp_14 (Pointnet_FP) multiple                  41536     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  8320      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  1161      \n",
      "=================================================================\n",
      "Total params: 574,665\n",
      "Trainable params: 574,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = PointNet4ALSModel(batch_size=1, num_classes=9)\n",
    "\n",
    "model.build(input_shape=(1, 100000, 6))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.001),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should train PointNet++ with the provided data for 10 to 20 epochs. But be aware that each epoch takes almost 20 minutes.\n",
    "\n",
    "But also for 5 epochs, you should already see quite good results.\n",
    "\n",
    "Note that no validation data and metric is defined. It makes not much sense on this small dataset and the large overlaps of the patches. But in real-life scenario, one should always use validation data that is independent of the training data and the test data. So, basically we are training with one (or rather two) blind eye(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "420/420 [==============================] - 1024s 2s/step - loss: 0.9053 - sparse_categorical_accuracy: 0.6946\n",
      "Epoch 2/5\n",
      "420/420 [==============================] - 1025s 2s/step - loss: 0.4899 - sparse_categorical_accuracy: 0.8327\n",
      "Epoch 3/5\n",
      "420/420 [==============================] - 1025s 2s/step - loss: 0.3721 - sparse_categorical_accuracy: 0.8706\n",
      "Epoch 4/5\n",
      "420/420 [==============================] - 1025s 2s/step - loss: 0.3197 - sparse_categorical_accuracy: 0.8881\n",
      "Epoch 5/5\n",
      "420/420 [==============================] - 1024s 2s/step - loss: 0.2732 - sparse_categorical_accuracy: 0.9034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f08a014bb90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=xyz, \n",
    "    y=labels,\n",
    "    batch_size=1,\n",
    "    epochs = 5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model\n",
    "\n",
    "You can save your model after training a few epochs for later use. Just uncomment the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('./checkpoints/PointNet++')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model\n",
    "\n",
    "And load it at a later time. Just execute all cells above with the exception of the cells with model.fit() and to save the model. After loading, you can train for more epochs with the cell that contains the fit() method or continue on below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('./checkpoints/PointNet++')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate with single patches\n",
    "\n",
    "Evaluate the performance with the 42 patches of the evaluation dataset of ISPRS. Points in the overlap region will be evaluated repeatedly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 100000, 6)\n",
      "(42, 100000, 1)\n"
     ]
    }
   ],
   "source": [
    "xyz_val, labels_val = load_data_from_csv(os.path.join(data_dir, 'patches', 'Vaihingen3D_Evaluation*.csv'))\n",
    "    \n",
    "print(xyz_val.shape)\n",
    "print(labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your accuracy should be close to (but probably below) 80%. (More like 78%.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 93s 2s/step - loss: 0.6676 - sparse_categorical_accuracy: 0.7985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6676174998283386, 0.7984952330589294]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xyz_val, labels_val, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine and evaluate all patches\n",
    "\n",
    "In the following, the patches are evaluated, then the results combines (with averaged class probabilities).\n",
    "\n",
    "The following code is very rough and not suited for studying. It is meant to just execute and output the point clouds to study in CloudCompare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 100000, 6)\n",
      "(42, 100000, 1)\n",
      "(42, 100000)\n"
     ]
    }
   ],
   "source": [
    "xyz_val, labels_val, indices_val = load_data_from_csv(os.path.join(data_dir, 'patchesIndexed', 'Vaihingen3D_Evaluation*.csv'), indices=True)\n",
    "    \n",
    "print(xyz_val.shape)\n",
    "print(labels_val.shape)\n",
    "print(indices_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 93s 2s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(xyz_val, batch_size=1, verbose=1)\n",
    "prd = np.reshape(predictions, (-1, 9))\n",
    "idx = indices_val.flatten()\n",
    "idx_arr = np.argsort(idx)\n",
    "prd_sorted = np.take(prd, idx_arr, axis=0)\n",
    "idx_arr_sorted = np.take(idx, idx_arr)\n",
    "u, indices, counts = np.unique(idx_arr_sorted, return_index=True, return_counts=True)\n",
    "added_pred = np.add.reduceat(prd_sorted, indices)\n",
    "pred_avg = added_pred / np.repeat(counts[:, np.newaxis], 9, axis=1)\n",
    "pred_labels_from_avg = np.argmax(pred_avg, axis=1)\n",
    "u, counts = np.unique(pred_labels_from_avg, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load original points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_dir = str(Path.home()) + r'/coursematerial/GIS/ISPRS/PointNet'\n",
    "\n",
    "column_names = ['x', 'y', 'z', 'intensity', 'return_number', 'number_of_returns', 'labels']\n",
    "        \n",
    "df_isprs_val = pd.read_csv(os.path.join(pn_dir, 'Vaihingen3D_Evaluation.pts'), sep=' ', names=column_names, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report\n",
    "\n",
    "You should see a better accuracy with the merged patches. Accuracy should be a little higher than 80%. (If you adapted the model and got more than 83%, then please tell us what you did!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "          Powerline       0.86      0.54      0.66       600\n",
      "     Low vegetation       0.84      0.80      0.82     98690\n",
      "Impervious surfaces       0.86      0.95      0.90    101986\n",
      "                Car       0.88      0.37      0.52      3708\n",
      "        Fence/Hedge       0.39      0.15      0.22      7422\n",
      "               Roof       0.88      0.94      0.91    109048\n",
      "             Facade       0.55      0.49      0.52     11224\n",
      "              Shrub       0.41      0.30      0.35     24818\n",
      "               Tree       0.76      0.78      0.77     54226\n",
      "\n",
      "           accuracy                           0.82    411722\n",
      "          macro avg       0.71      0.59      0.63    411722\n",
      "       weighted avg       0.80      0.82      0.81    411722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_names = ['Powerline', 'Low vegetation', 'Impervious surfaces', 'Car', 'Fence/Hedge', 'Roof', 'Facade', 'Shrub', 'Tree']\n",
    "print(classification_report(df_isprs_val['labels'], pred_labels_from_avg, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Powerline</th>\n",
       "      <th>Low vegetation</th>\n",
       "      <th>Impervious surfaces</th>\n",
       "      <th>Car</th>\n",
       "      <th>Fence/Hedge</th>\n",
       "      <th>Roof</th>\n",
       "      <th>Facade</th>\n",
       "      <th>Shrub</th>\n",
       "      <th>Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Powerline</th>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low vegetation</th>\n",
       "      <td>0</td>\n",
       "      <td>78538</td>\n",
       "      <td>12369</td>\n",
       "      <td>46</td>\n",
       "      <td>340</td>\n",
       "      <td>1948</td>\n",
       "      <td>1174</td>\n",
       "      <td>3426</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Impervious surfaces</th>\n",
       "      <td>0</td>\n",
       "      <td>4561</td>\n",
       "      <td>96495</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>764</td>\n",
       "      <td>39</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Car</th>\n",
       "      <td>0</td>\n",
       "      <td>403</td>\n",
       "      <td>859</td>\n",
       "      <td>1372</td>\n",
       "      <td>345</td>\n",
       "      <td>231</td>\n",
       "      <td>48</td>\n",
       "      <td>448</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence/Hedge</th>\n",
       "      <td>0</td>\n",
       "      <td>1005</td>\n",
       "      <td>463</td>\n",
       "      <td>71</td>\n",
       "      <td>1133</td>\n",
       "      <td>560</td>\n",
       "      <td>64</td>\n",
       "      <td>3144</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roof</th>\n",
       "      <td>17</td>\n",
       "      <td>1052</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>102753</td>\n",
       "      <td>1090</td>\n",
       "      <td>576</td>\n",
       "      <td>3302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facade</th>\n",
       "      <td>20</td>\n",
       "      <td>1024</td>\n",
       "      <td>308</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2569</td>\n",
       "      <td>5543</td>\n",
       "      <td>538</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shrub</th>\n",
       "      <td>5</td>\n",
       "      <td>5865</td>\n",
       "      <td>721</td>\n",
       "      <td>62</td>\n",
       "      <td>799</td>\n",
       "      <td>2453</td>\n",
       "      <td>553</td>\n",
       "      <td>7503</td>\n",
       "      <td>6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tree</th>\n",
       "      <td>10</td>\n",
       "      <td>1404</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>289</td>\n",
       "      <td>5622</td>\n",
       "      <td>1647</td>\n",
       "      <td>2741</td>\n",
       "      <td>42398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Powerline  Low vegetation  Impervious surfaces   Car  \\\n",
       "Powerline                  323               1                    0     0   \n",
       "Low vegetation               0           78538                12369    46   \n",
       "Impervious surfaces          0            4561                96495    11   \n",
       "Car                          0             403                  859  1372   \n",
       "Fence/Hedge                  0            1005                  463    71   \n",
       "Roof                        17            1052                  239     0   \n",
       "Facade                      20            1024                  308     2   \n",
       "Shrub                        5            5865                  721    62   \n",
       "Tree                        10            1404                  111     4   \n",
       "\n",
       "                     Fence/Hedge    Roof  Facade  Shrub   Tree  \n",
       "Powerline                      0     236       6     14     20  \n",
       "Low vegetation               340    1948    1174   3426    849  \n",
       "Impervious surfaces            1     764      39    111      4  \n",
       "Car                          345     231      48    448      2  \n",
       "Fence/Hedge                 1133     560      64   3144    982  \n",
       "Roof                          19  102753    1090    576   3302  \n",
       "Facade                        13    2569    5543    538   1207  \n",
       "Shrub                        799    2453     553   7503   6857  \n",
       "Tree                         289    5622    1647   2741  42398  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = ['Powerline', 'Low vegetation', 'Impervious surfaces', 'Car', 'Fence/Hedge', 'Roof', 'Facade', 'Shrub', 'Tree']\n",
    "\n",
    "cm = confusion_matrix(df_isprs_val['labels'], pred_labels_from_avg)\n",
    "\n",
    "df = pd.DataFrame(data=cm, columns=class_names, index=class_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output colorized point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored_point_cloud(xyz, y, filename):\n",
    "\n",
    "    color_map = np.array([\n",
    "        [255, 255, 125],\n",
    "        [  0, 255, 255],\n",
    "        [255, 255, 255],\n",
    "        [255, 255,   0],\n",
    "        [  0, 255, 125],\n",
    "        [  0,   0, 255],\n",
    "        [  0, 125, 255],\n",
    "        [125, 255,   0],\n",
    "        [  0, 255,   0]])\n",
    "    \n",
    "    u, inverses = np.unique(y, return_inverse=True)    \n",
    "    \n",
    "    colors = color_map[inverses]\n",
    "    \n",
    "    r_s = pd.Series(data=colors[:,0], name='red')\n",
    "    g_s = pd.Series(data=colors[:,1], name='green')\n",
    "    b_s = pd.Series(data=colors[:,2], name='blue')\n",
    "\n",
    "    df = pd.DataFrame(xyz, columns=['x', 'y', 'z'])    \n",
    "\n",
    "    df['red'] = r_s\n",
    "    df['green'] = g_s\n",
    "    df['blue'] = b_s\n",
    "    \n",
    "    df.to_csv(filename, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored_point_cloud(df_isprs_val[['x', 'y', 'z']], pred_labels_from_avg, 'CombinedResult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For expert students with too much time:\n",
    "\n",
    "The ISPRS datasets also contains aerial images. One could overlay the aerial images with the point clouds (using e.g. LAStools) to also have color information as additional input features. If someone is interested, we could provide some guidance for the point cloud and image fusion using LAStools, and we could provide the rough code for the generation of the patches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}