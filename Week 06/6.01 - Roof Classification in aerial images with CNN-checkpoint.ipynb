{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 06.1 - Image Classfication with a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup DevCube GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can start, you have to find a GPU on the system that is not heavily used by other users. Otherwise you cannot initialize your neural network.\n",
    "\n",
    "\n",
    "**Hint:** the command is **nvidia-smi**, just in case it is displayed above in two lines because of a line break.\n",
    "\n",
    "As a result you get a summary of the GPUs available in the system, their current memory usage (in MiB for megabytes), and their current utilization (in %). There should be six or eight GPUs listed and these are numbered 0 to n-1 (n being the number of GPUs). The GPU numbers (ids) are quite at the beginning of each GPU section and their numbers increase from top to bottom by 1.\n",
    "\n",
    "Find a GPU where the memory usage is low. For this purpose look at the memory usage, which looks something like '365MiB / 16125MiB'. The first value is the already used up memory and the second value is the total memory of the GPU. Look for a GPU where there is a large difference between the first and the second value.\n",
    "\n",
    "**Remember the GPU id and write it in the next line instead of the character X.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change X to the GPU number you want to use,\n",
    "# otherwise you will get a Python error\n",
    "# e.g. USE_GPU = 4\n",
    "USE_GPU = 0 # YOUR_CHOICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose one GPU\n",
    "\n",
    "**The following code is very important and must always be executed before using TensorFlow in the exercises, so that only one GPU is used and that it is set in a way that not all its memory is used at once. Otherwise, the other students will not be able to work with this GPU.**\n",
    "\n",
    "The following program code imports the TensorFlow library for Deep Learning and outputs the version of the library.\n",
    "\n",
    "Then, TensorFlow is configured to only see the one GPU whose number you wrote in the above cell (USE_GPU = X) instead of the X.\n",
    "\n",
    "Finally, the GPU is set so that it does not immediately reserve all memory, but only uses more memory when needed. \n",
    "\n",
    "(The comments within the code cell explains a bit of what is happening if you are interested to better understand it. See also the documentation of TensorFlow for an explanation of the used methods.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.0\n",
      "\n",
      "Available GPU Devices:\n",
      "\n",
      "Visible GPU Devices:\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow \n",
    "import tensorflow as tf\n",
    "\n",
    "# Print the installed TensorFlow version\n",
    "print(f'TensorFlow version: {tf.__version__}\\n')\n",
    "\n",
    "# Get all GPU devices on this server\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Print the name and the type of all GPU devices\n",
    "print('Available GPU Devices:')\n",
    "for gpu in gpu_devices:\n",
    "    print(' ', gpu.name, gpu.device_type)\n",
    "    \n",
    "# Set only the GPU specified as USE_GPU to be visible\n",
    "# tf.config.set_visible_devices(gpu_devices[USE_GPU], 'GPU')\n",
    "\n",
    "# Get all visible GPU  devices on this server\n",
    "visible_devices = tf.config.get_visible_devices('GPU')\n",
    "\n",
    "# Print the name and the type of all visible GPU devices\n",
    "print('\\nVisible GPU Devices:')\n",
    "for gpu in visible_devices:\n",
    "    print(' ', gpu.name, gpu.device_type)\n",
    "    \n",
    "# Set the visible device(s) to not allocate all available memory at once,\n",
    "# but rather let the memory grow whenever needed\n",
    "for gpu in visible_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please run this cell in order to have the plots displayed in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification with Convolutional  Neural Networks\n",
    "\n",
    "In this section perform roof classification in aerial images using Convolutional.\n",
    "Since the available dataset is of reduced size for the requirements on DL models, your model would benefit from applying the introduced regularization techniques in order to prevent your model from overfitting. \n",
    "\n",
    "\n",
    "\n",
    "### Learning Objectives:\n",
    "\n",
    "+ Build independently a Convolutional Neural network for classification of aerial images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs basics\n",
    "* the input to a CNN is a (single) `4 rank tensor (nr_samples_nr, im_height, im_width, nr_channels)`\n",
    "\n",
    " \n",
    " #### Convolutional layers\n",
    " \n",
    " A convolutional layer performs the following operations:\n",
    " \n",
    "- Takes an input volume \n",
    "- Applies a filter at every position of the input\n",
    "- Outputs another volume (usually of different size)\n",
    "<center><img src=\"images/Convolution_schematic.gif\" style=\"width:500px;height:300px;\"></center>\n",
    "    \n",
    " The _main_ parameters are of a [convolutional layer](https://keras.io/layers/convolutional/) in keras are:\n",
    "\n",
    "1. `filters` - the number of output channels (the number of convolutions you want to generate). Purely arbitrary, but good to start with something in the order of 32\n",
    "2. `kernel_size` - the shape of the convolutional filter, in this case a 3x3 grid\n",
    "3. `activation` - the activation function to use -- in this case we'll use relu, which you might recall is the equivalent of returning x when x>0, else returning 0\n",
    "4. `input_shape`- only for the first layer, the shape of the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling layers\n",
    "\n",
    "A Convolutional layer is commonly followed by a `pooling layer`.\n",
    "Applying (POOL) layer reduces the height and width of the input. It helps reduce computation costs, as well as helps make feature detectors more invariant to its position in the input. The most common type of pooling layers is `Max-pooling layer`:\n",
    "* slides an ($f, f$) window over the input and stores the max value of the window in the output.\n",
    "<center><img src=\"./images/max_pool1.png\" style=\"width:500px;height:300px;\"></center>\n",
    "\n",
    "- Max-pooling layer: slides an ($f, f$) window over the input and stores the max value of the window in the output\n",
    "The main parameters of [pool layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) in TensorFlow.keras are:\n",
    "- `pool_size` - the shape of the pooling filter,specifies the height and width of the fxf window you would compute a max or average over, commonly (2,2)\n",
    "###### Important observation:\n",
    "* pooling layers have no parameters for backpropagation to train. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Dataset\n",
    "\n",
    "For more information about the dataset used in this exercise, please check exercies 5.04 - Roof classification in aerial images. \n",
    "\n",
    "We assume that the dataset resides and is used in the coursematerial folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = str(Path.home()) + r'/coursematerial/GIS/dataset_img_building_roofs/'\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "validation_dir = os.path.join(data_dir, 'validation')\n",
    "test_dir = os.path.join(data_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of training images belonging to flat_roof_class :', len(os.listdir(os.path.join(train_dir,'flat_roof'))))\n",
    "print('Number of training belonging to hip_roof_class:', len(os.listdir(os.path.join(train_dir,'hip_roof'))))\n",
    "print('Number of training images belonging to other_roof_types_class:', len(os.listdir(os.path.join(train_dir,'other_roof'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generators Setup \n",
    "\n",
    "You'll have one generator for the _training images_, one for the _validation images_ and one for _test images_. Your generators will yield batches of images of size 64x64 and their categorical labels. One feature of the image generator is that we can point it at **a parent directory** (in our example called `train_dir`, `validation_dir` and `validation_dir`respectively) and then the **sub-directories** of that will automatically **generate labels** for you. \n",
    "Please notice, your images dataset is already split (no need of split fraction) and stored in different directories. When using _flow_from_directory_method_ please point to the right directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting some hyperparameters\n",
    "NR_OF_IMAGES = 294\n",
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = int(NR_OF_IMAGES/BATCH_SIZE)\n",
    "IMAGE_WIDTH = 128 \n",
    "IMAGE_HEIGHT = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a _ImageDataGenerator_ object for your training images that:\n",
    "\n",
    " * scales the images\n",
    "\n",
    " * specify several transformations to be applied on the original images in order to augment the dataset\n",
    " \n",
    " \n",
    " Call _flow_from_directory_ on this object and save the function in a variable _train_generator_.\n",
    " * specify the target directory\n",
    " * pass in the size of the images \n",
    " * specify the batch size \n",
    " * specify the class_mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All images will be rescaled by 1./255\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range = 30, width_shift_range = 0.2, \n",
    "                                   height_shift_range=0.2, horizontal_flip=True) # create an image generator instance\n",
    "\n",
    "print(\"\\nData generator for training data:\")\n",
    "train_generator =  train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 64x64\n",
    "        target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        batch_size = BATCH_SIZE,\n",
    "        # Since we use categorical_crossentropy loss, we need categorical labels \n",
    "        class_mode='categorical') # we would pass in 'binary' for binary classfication (2 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a _ImageDataGenerator_ object for your validation images that:\n",
    "\n",
    " * scales the images </br>\n",
    " \n",
    "Call _flow_from_directory_ on this object and save the function in a variable _validation_generator_.\n",
    " * specify the target directory\n",
    " * pass in the size of the images \n",
    " * specify the batch size \n",
    " * specify the class_mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)        \n",
    "print(\"\\nData generator for validation data:\")\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        batch_size= BATCH_SIZE,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a _ImageDataGenerator_ object for your test images that:\n",
    "\n",
    " * scales the images </br>\n",
    " \n",
    "Call _flow_from_directory_ on this object and save the function in a variable _test_generator_.\n",
    " * specify the target directory\n",
    " * pass in the size of the images \n",
    " * specify the batch size \n",
    " * specify the class_mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "print(\"\\nData generator for test data:\")\n",
    "print(\"\\nData generator for test data:\")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task 01 -Build the Convolutional Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1) Instantiate a model object from tf.keras Sequential class\n",
    "\n",
    "2) Use repeatedly the add method on this object to add a stack convolutional, pooling layers as follows:\n",
    "\n",
    "* one `conv layer` [tf.keras.layers.Conv2D()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) - passing the following args: - number of filters: 32, filter_shape: (3,3), activation:'relu', input_shape \n",
    "* one `max_pool layer`[tf.keras.layers.MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D), pass the pool_size arg: (2,2) \n",
    "* one `conv layer` [tf.keras.layers.Conv2D()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) - passing the following args: - number of filters: 64, filter_shape: (3,3), activation:'relu'\n",
    "* one `max_pool layer`[tf.keras.layers.MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D), pass the pool_size arg: (2,2)\n",
    "* faltten the output of the previous layer using: [tf.keras.layers.Flatten(https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)] (This will allow to add a fully connected layer)\n",
    "* one fully connected layer [tf.keras.layers.Dense](tf.keras.layers.Dense), pass as args: 128 output neuron units, activation 'relu'\n",
    "* output layer:  one fully connected layer [tf.keras.layers.Dense](tf.keras.layers.Dense), pass as args: 10 output neuron units (the number of categories in the dataset, activation 'softmax'\n",
    "\n",
    "Schematically your model can be represented as below:\n",
    "\n",
    "<img src =\"images/Convolution model .png\">\n",
    "\n",
    "The base model can be improved by increasing the number of layers / filters. After running the base configuration, try to experiment with other network configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, ReLU, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "input_shape=(128,128,3)\n",
    "\n",
    "\n",
    "# model = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 02: Define callabacks\n",
    "\n",
    "* define a tf.keras callback [EarlyStopping object](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) that:\n",
    "        -  will stop the training after no improvement in val_accuracy for a number of 12 Epoch and \n",
    "        -  saves the best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "my_callbacks = # YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TASK 3: Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now compile the model using the `compile` method. Remember that you need to specify an optimizer, a loss function and a metric to judge the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.compile( # YOUR CODE HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TASK 4: Fit the model to the training data\n",
    "\n",
    "Now you should train the model on the *Building Roofs dataset* by calling the  `fit()` method on the compiled model object.\n",
    "* Pass in the `train_generator`to the model's `fit` method.\n",
    "* Pass in `STEPS_PER_EPOCH` defined before to the `steps_per_epoch` argument.\n",
    "* Pass in the 'validation_generator' to the `validation_data` argument. \n",
    "* Run the training for a number of 100 epochs, passed in to the function's `epochs` argument.\n",
    "* Set the value of the `shuffle` argument to  `True`\n",
    "* Assign the output of the fit method to a variable 'history'  to be used for plotting the learning curves.\n",
    "* Pass in you callbacks list to the callbacks arguments\n",
    "For refreshing the possible arguments of the `fit()`method please read the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history =  # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves\n",
    "\n",
    "We will now plot two graphs:\n",
    "* Epoch vs accuracy\n",
    "* Epoch vs loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to plot the epoch vs accuracy graph\n",
    "\n",
    "try:\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "except KeyError:\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "plt.title('Accuracy vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell to plot the epoch vs loss graph\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the class for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "first_batch_of_test_set = test_generator[0]\n",
    "images, labels = first_batch_of_test_set\n",
    "img = images[0] #first_image_in_batch\n",
    "\n",
    "_ = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction on one image\n",
    "classif_prob = model.predict(img)\n",
    "print(classif_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the element of the highest probability\n",
    "pred_classes_argmax = np.argmax(classif_prob,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have one image, get the index of the predicted class.\n",
    "predicted_cls = pred_classes_argmax[0]\n",
    "print(\"Predicted class:\", predicted_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class label using the Keras data generator\n",
    "for index,cls in train_generator.class_indices.items():\n",
    "    if cls == predicted_cls:\n",
    "        class_label = index\n",
    "class_label\n",
    "print(class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get example image. The first image of the predicted class folder\n",
    "example_img_path = os.listdir(os.path.join(train_dir,class_label))[0]\n",
    "example_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get example image full path\n",
    "example_img_full_path = os.path.join(train_dir,class_label,example_img_path)\n",
    "example_img_full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predicted class example\n",
    "img = image.load_img(example_img_full_path, target_size=(64, 64))\n",
    "_= plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A closer look at classification scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = model.predict(test_generator,2)\n",
    "\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = np.argmax(classifications[0])\n",
    "print('Predicted class:{}'.format(predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(\"{}:{},{}:{}.\".format(model.metrics_names[0],values[0],model.metrics_names[1],values[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Further practice:\n",
    "\n",
    "Improve your model:\n",
    "\n",
    "* Add another Conv (128 filters) + Pool layers\n",
    "* Increase the number of units of the Dense layer to 256.\n",
    "* Add an Dropout layer after the fully connected layer.\n",
    "* Re-train the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
